{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of ASR Systems Using WER\n",
    "\n",
    "This notebook demonstrates the evaluation of Automatic Speech Recognition (ASR) systems using the Word Error Rate (WER) metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Word Error Rate\n",
    "\n",
    "Word Error Rate (WER) is a crucial metric used to evaluate the performance of an Automatic Speech Recognition (ASR) system. It measures how accurately the ASR system transcribes spoken language into text by comparing the machine-generated transcription to a human-generated reference transcription.\n",
    "\n",
    "The formula for WER is:\n",
    "\n",
    "$$ WER = \\frac{S + D + I}{N} $$\n",
    "\n",
    "Where:\n",
    "- \\( S \\) represents the number of substitutions, which occur when a word from the reference is replaced by a different word in the hypothesis.\n",
    "- \\( D \\) represents the number of deletions, where a word from the reference is missing in the hypothesis.\n",
    "- \\( I \\) represents the number of insertions, where a word not present in the reference appears in the hypothesis.\n",
    "- \\( N \\) is the total number of words in the reference transcription.\n",
    "\n",
    "The WER gives us a percentage that reflects the proportion of errors (substitutions, deletions, and insertions) in the hypothesis compared to the total number of words in the reference. A WER of 0% means perfect transcription, while a higher WER indicates more discrepancies between the hypothesis and the reference.\n",
    "\n",
    "### Intuition behind WER\n",
    "\n",
    "WER is designed to provide a simple, yet effective way to quantify the performance of an ASR system. The metric helps us understand how well a system understands and processes natural language in spoken form. By identifying how many changes one would need to make to transform the hypothesis into the reference, WER offers insights into both the accuracy and reliability of the ASR system.\n",
    "\n",
    "Additionally, analyzing the types of errors (substitutions, deletions, and insertions) can help developers fine-tune the ASR algorithms, focusing on reducing specific kinds of errors that are more prevalent or more impactful on the user experience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Next, we take a look at calculating WER in Python. First, let's install `jiwer` for calculating the Word Error Rate.\n",
    "\n",
    "```bash\n",
    "pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import jiwer  # This is a simple library to calculate WER\n",
    "\n",
    "# Ensure that PyTorch is installed\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Data\n",
    "\n",
    "We will use a set of simulated transcriptions and their references to illustrate how WER is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "references = [\n",
    "    \"hello world\",\n",
    "    \"this is a test\",\n",
    "    \"the quick brown fox jumps over the lazy dog\"\n",
    "]\n",
    "\n",
    "hypotheses = [\n",
    "    \"helo world\",\n",
    "    \"this is test\",\n",
    "    \"the quick brown fox jump over the lazy\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference 1: hello world\n",
      "Hypothesis 1: helo world\n",
      "WER: 50.00%\n",
      "\n",
      "Reference 2: this is a test\n",
      "Hypothesis 2: this is test\n",
      "WER: 25.00%\n",
      "\n",
      "Reference 3: the quick brown fox jumps over the lazy dog\n",
      "Hypothesis 3: the quick brown fox jump over the lazy\n",
      "WER: 22.22%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate WER\n",
    "def calculate_wer(references, hypotheses):\n",
    "    wer_scores = []\n",
    "    for ref, hyp in zip(references, hypotheses):\n",
    "        wer_score = jiwer.wer(ref, hyp)\n",
    "        wer_scores.append(wer_score)\n",
    "    return wer_scores\n",
    "\n",
    "# Calculate WER for each pair\n",
    "wer_scores = calculate_wer(references, hypotheses)\n",
    "\n",
    "# Display the results\n",
    "for i, score in enumerate(wer_scores):\n",
    "    print(f\"Reference {i+1}: {references[i]}\")\n",
    "    print(f\"Hypothesis {i+1}: {hypotheses[i]}\")\n",
    "    print(f\"WER: {score:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of WER Results\n",
    "\n",
    "#### Example 1:\n",
    "- **Reference**: \"hello world\"\n",
    "- **Hypothesis**: \"helo world\"\n",
    "- **WER**: 50.00%\n",
    "\n",
    "**Breakdown**:\n",
    "- **Substitutions**: 0 (No words were wrongly replaced; \"hello\" was shortened but not replaced)\n",
    "- **Deletions**: 0 (All words in the reference appear in the hypothesis)\n",
    "- **Insertions**: 0 (No extra words were added)\n",
    "- **Modifications**: 1 (\"hello\" was misspelled as \"helo\")\n",
    "- **Total Words in Reference (N)**: 2\n",
    "\n",
    "In this case, there is one modification (misspelling), which is treated as a substitution in WER calculation. Since there is 1 error and there are 2 reference words:\n",
    "\n",
    "$$ WER = \\frac{1}{2} = 50\\% $$\n",
    "\n",
    "This high WER reflects a significant error given the short length of the reference.\n",
    "\n",
    "#### Example 2:\n",
    "- **Reference**: \"this is a test\"\n",
    "- **Hypothesis**: \"this is test\"\n",
    "- **WER**: 25.00%\n",
    "\n",
    "**Breakdown**:\n",
    "- **Substitutions**: 0\n",
    "- **Deletions**: 1 (\"a\" is missing in the hypothesis)\n",
    "- **Insertions**: 0\n",
    "- **Total Words in Reference (N)**: 4\n",
    "\n",
    "The hypothesis is missing one word:\n",
    "\n",
    "$$ WER = \\frac{1}{4} = 25\\% \\$$\n",
    "\n",
    "The WER indicates that to make the hypothesis match the reference, 25% of the reference words need to be considered.\n",
    "\n",
    "#### Example 3:\n",
    "- **Reference**: \"the quick brown fox jumps over the lazy dog\"\n",
    "- **Hypothesis**: \"the quick brown fox jump over the lazy\"\n",
    "- **WER**: 22.22%\n",
    "\n",
    "**Breakdown**:\n",
    "- **Substitutions**: 0\n",
    "- **Deletions**: 1 (\"jumps\" to \"jump\" - treating as a grammatical error involving pluralization)\n",
    "- **Insertions**: 0\n",
    "- **Total Words in Reference (N)**: 9\n",
    "\n",
    "Again, there's one deletion:\n",
    "\n",
    "$$ WER = \\frac{1}{9} \\approx 22.22\\% $$\n",
    "\n",
    "This WER indicates that about 22.22% of the reference words are in error due to the hypothesis's lack of alignment with the reference, which in this case is the missing plural form.\n",
    "\n",
    "#### Summary\n",
    "WER effectively quantifies the errors in transcription relative to the length of the spoken content. A low WER is desirable, indicating fewer errors relative to the total words. These examples illustrate how even a single missing word or a misspelling significantly impacts WER, especially in shorter sentences. Each type of error—whether a substitution, deletion, or insertion—equally affects the calculation, emphasizing the importance of accuracy in each word for ASR systems.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
