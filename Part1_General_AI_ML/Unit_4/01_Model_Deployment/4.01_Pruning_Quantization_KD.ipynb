{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Model Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Model Efficiency Matters\n",
    "\n",
    "In the context of AI, efficiency is not just about speed; it's about making AI accessible and practical for everyday applications. The size and complexity of deep learning models have grown tremendously. While this leads to improved performance, it creates challenges for deployment, especially on mobile devices, embedded systems, or any setting where computational resources or power are limited. Model efficiency techniques aim to address these challenges without sacrificing accuracy.\n",
    "\n",
    "Growing model complexity poses challenges:\n",
    "- Storage: Large models consume more storage space.\n",
    "- Inference Speed: Complex models take longer to process inputs.\n",
    "- Energy Consumption: Computationally demanding models drain batteries quickly.\n",
    "- Deployment: Resource-constrained devices (smartphones, IoT) struggle with large models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pruning\n",
    "Pruning identifies and removes the less important weights of a neural network that have minimal impact on its output. This creates a sparser and more streamlined model. \n",
    "Unstructured pruning zero-out the least important weights, while structured pruning can be more aggressive by removing full sections of the network.\n",
    "\n",
    "Benefits:\n",
    "- Reduces model size\n",
    "- Can improve inference speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/pruning.webp\" alt=\"drawing\" width=\"450\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch includes functionality for both structured and unstructured pruning. Here, we'll show an example of unstructured pruning, which removes individual weights in the model. This example demonstrates how to randomly prune 30% of the connections in the first linear layer of the network by setting their weights to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model: Net(\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "Pruned model: Net(\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "# Define a simple model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "print(\"Original model:\", model)\n",
    "\n",
    "# Apply pruning to the first layer\n",
    "prune.random_unstructured(model.fc1, name='weight', amount=0.3)\n",
    "\n",
    "# Check the pruned model\n",
    "print(\"Pruned model:\", model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quantization\n",
    "Quantization simplifies the model's mathematical operations, converting those high-precision calculations into something more manageable and, crucially, faster. It  reduces the storage footprint of models by using less precise data types such as representing model weights and activations using lower-precision numbers (e.g., 8-bit integers instead of 32-bit floating-point)\n",
    "\n",
    "Benefits:\n",
    "- Reduces model size\n",
    "- Accelerates computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/quantization.jpeg\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of quantization on the same simple model as before. This code dynamically quantizes the linear layers of the model to int8 precision, which is particularly useful for reducing model size and speeding up inference for AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model: Net(\n",
      "  (fc1): DynamicQuantizedLinear(in_features=128, out_features=64, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      "  (fc2): DynamicQuantizedLinear(in_features=64, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.quantization\n",
    "\n",
    "import torch\n",
    "torch.backends.quantized.engine = 'qnnpack'  # For ARM architectures\n",
    "\n",
    "\n",
    "# Define a simple model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Specify the model and the sample input size for dynamic quantization\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "print(\"Quantized model:\", quantized_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Knowledge Distillation\n",
    "Knowledge distillation involves training a smaller (student) model to replicate the behavior of a larger (teacher) model. The teacher model produces \"soft labels\" (probabilistic outputs). Student model is trained to match the soft labels, not just the original dataset's hard labels.\n",
    "\n",
    "Benefits:\n",
    "- Compresses knowledge into a smaller, more efficient model\n",
    "- Potential for higher accuracy than training the student directly on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/kd.jpeg\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simplified example of how to set this up in PyTorch. In this example, we use a pretrained ResNet18 model from torchvision as the teacher model, demonstrating knowledge distillation to a simpler student model on the CIFAR-10 dataset. The ResNet18 model is pretrained on ImageNet, so we'll adapt it to work with CIFAR-10.\n",
    "\n",
    "The teacher model is set to evaluation mode to ensure it does not update its weights during training.\n",
    "The loss function (CrossEntropyLoss) and optimizer (SGD with learning rate 0.001 and momentum 0.9) are defined for training the student model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch: 1, Batch: 50, Loss: 2.2586119604110717\n",
      "Epoch: 1, Batch: 100, Loss: 2.161914668083191\n",
      "Epoch: 2, Batch: 50, Loss: 2.073851742744446\n",
      "Epoch: 2, Batch: 100, Loss: 2.0345424127578737\n",
      "Finished Training Student Model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define a simpler student model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(8 * 16 * 16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 8 * 16 * 16)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Adjusting the ResNet model to CIFAR-10's resolution\n",
    "class ResNetForCIFAR10(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNetForCIFAR10, self).__init__()\n",
    "        original_model = resnet18(pretrained=pretrained)\n",
    "        self.features = nn.Sequential(*list(original_model.children())[:-2])\n",
    "        self.adapted_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.adapted_avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "teacher_model = ResNetForCIFAR10()\n",
    "teacher_model.eval()  # Set the teacher model to evaluation mode\n",
    "\n",
    "student_model = SimpleCNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(2):  # Iterate over 2 epochs\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        if i >= 100:  # Limit the number of batches to speed up training\n",
    "            break\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs_student = student_model(inputs)\n",
    "        with torch.no_grad():\n",
    "            outputs_teacher = teacher_model(inputs)\n",
    "\n",
    "        loss = criterion(outputs_student, labels) + nn.KLDivLoss()(nn.functional.log_softmax(outputs_student, dim=1),\n",
    "                                                                   nn.functional.softmax(outputs_teacher, dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:  # Print every 50 mini-batches\n",
    "            print(f'Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 50}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training Student Model')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
