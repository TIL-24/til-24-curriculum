{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Common Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn\n",
    "\n",
    "Scikit-learn is widely used for traditional machine learning algorithms, including classification, regression, clustering, and dimensionality reduction. \\\n",
    "![Scikit Learn](imgs/sklearn.png) \\\n",
    "https://scikit-learn.org/stable/\n",
    "\n",
    "\n",
    "\n",
    "### **Installation**\n",
    "\n",
    "```bash\n",
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classification with Scikit-learn**\n",
    "Classification is a supervised learning approach where the goal is to predict the categorical class labels of new observations, based on past observations.\n",
    "\n",
    "Example: Iris Dataset Classification\n",
    "- The Iris dataset is a classic dataset for classification. It consists of 150 observations of iris flowers from three different species. Each observation has four features: sepal length, sepal width, petal length, and petal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% testing\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Regression with Scikit-learn**\n",
    "Regression analysis is a type of predictive modelling technique which investigates the relationship between a dependent (target) and independent variable(s).\n",
    "\n",
    "Example: Diabetes Dataset Regression\n",
    "-The diabetes dataset consists of 10 physiological variables (age, sex, weight, blood pressure) measure on 442 patients, and an indication of disease progression after one year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 3266.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Create linear regression object\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(X_test)\n",
    "\n",
    "# The mean squared error\n",
    "print('Mean squared error: %.2f'\n",
    "      % mean_squared_error(y_test, diabetes_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Clustering with Scikit-learn**\n",
    "Clustering is a type of unsupervised learning that groups together data points that are similar to each other.\n",
    "\n",
    "Example: K-Means Clustering\n",
    "- K-Means is a popular clustering algorithm that partitions n observations into k clusters in which each observation belongs to the cluster with the nearest mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted clusters: [1 0]\n",
      "Cluster Centers: [[10.  2.]\n",
      " [ 1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Generate artificial data\n",
    "X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "              [10, 2], [10, 4], [10, 0]])\n",
    "\n",
    "# Create KMeans object\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "\n",
    "# Predict the clusters\n",
    "predicted_clusters = kmeans.predict([[0, 0], [12, 3]])\n",
    "\n",
    "# Centers of the clusters\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "print(\"Predicted clusters:\", predicted_clusters)\n",
    "print(\"Cluster Centers:\", centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "\n",
    "PyTorch is an open-source machine learning library for Python developed by Facebook, widely used for applications such as computer vision and natural language processing. It is known for its flexibility, speed, and ease of use. PyTorch works with data in the form of tensors, which are similar to arrays and matrices. \\\n",
    "![Pytorch](imgs/pytorch.png) \\\n",
    "https://pytorch.org/\n",
    "\n",
    "\n",
    "### **Installation**\n",
    "\n",
    "```bash\n",
    "pip install torch torchvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Basic Tensor Operations**\n",
    "Tensors are the fundamental unit of data in PyTorch and represent a multi-dimensional array.\n",
    "\n",
    "Example: Creating Tensors and Basic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of x and y: tensor([5, 7, 9])\n",
      "Element-wise multiplication of x and y: tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Basic operations\n",
    "sum_xy = x + y  # Element-wise addition\n",
    "mul_xy = x * y  # Element-wise multiplication\n",
    "\n",
    "print(\"Sum of x and y:\", sum_xy)\n",
    "print(\"Element-wise multiplication of x and y:\", mul_xy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Simple Neural Network**\n",
    "This example gives a glimpse into defining and manipulating tensors, computing gradients, and a basic framework for a neural network model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.811100721359253\n",
      "Gradient w.r.t weights: tensor([[-0.0261],\n",
      "        [ 1.8886],\n",
      "        [ 1.9473]])\n",
      "Gradient w.r.t bias: tensor([-1.8974])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Random data for inputs (features) and outputs (targets)\n",
    "features = torch.randn((20, 3))  # 20 samples, 3 features\n",
    "targets = torch.randn((20, 1))  # 20 samples, 1 target\n",
    "\n",
    "# Weight and bias\n",
    "weights = torch.randn((3, 1), requires_grad=True)  # 3 features to 1 output\n",
    "bias = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# Simple linear model\n",
    "def model(x):\n",
    "    return x @ weights + bias  # @ represents matrix multiplication\n",
    "\n",
    "# Loss function (Mean Square Error)\n",
    "def mse(predictions, targets):\n",
    "    differences = predictions - targets\n",
    "    return torch.sum(differences * differences) / differences.numel()\n",
    "\n",
    "# Forward pass: compute predicted y by passing x to the model\n",
    "predictions = model(features)\n",
    "\n",
    "# Compute and print loss\n",
    "loss = mse(predictions, targets)\n",
    "print(\"Loss:\", loss.item())\n",
    "\n",
    "# Backpropagation\n",
    "loss.backward()\n",
    "print(\"Gradient w.r.t weights:\", weights.grad)\n",
    "print(\"Gradient w.r.t bias:\", bias.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow/Keras\n",
    "TensorFlow is an extensive ecosystem for machine learning and deep learning, while Keras is a high-level API for building and training deep learning models.\\\n",
    "![Tensorflow](imgs/tensorflow.png) \\\n",
    "https://www.tensorflow.org/\n",
    "\n",
    "\n",
    "\n",
    "### **Installation**\n",
    "\n",
    "```bash\n",
    "pip install tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 783us/step - loss: 0.2948 - accuracy: 0.9150\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 819us/step - loss: 0.1414 - accuracy: 0.9579\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1067 - accuracy: 0.9675\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 695us/step - loss: 0.0884 - accuracy: 0.9725\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 697us/step - loss: 0.0749 - accuracy: 0.9759\n",
      "313/313 [==============================] - 0s 445us/step - loss: 0.0711 - accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07107871770858765, 0.9775999784469604]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Load MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0  # Normalize data\n",
    "\n",
    "# Build the Sequential model\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face Transformers\n",
    "\n",
    "Hugging Face Transformers is a library that provides thousands of pre-trained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, and more. It is built on top of PyTorch, TensorFlow, and JAX, offering a high-level API for working with these models.\\\n",
    "![Hugging Face](imgs/hugging_face4.png) \\\n",
    "https://huggingface.co/\n",
    "\n",
    "\n",
    "\n",
    "### **Installation**\n",
    "\n",
    "```bash\n",
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Classification**\n",
    "Text classification involves assigning categories to text data. Here's how to perform sentiment analysis using a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9982925057411194}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the sentiment analysis pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\",model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Perform sentiment analysis\n",
    "result = classifier(\"I love using Transformers for NLP tasks!\")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Name Entity Recognition (NER)**\n",
    "Named Entity Recognition is the task of classifying named entities found in a text into pre-defined categories such as the names of persons, organizations, locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/waseem/Desktop/Files/Tribe/venv_ml/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Hugging Face | Type: ORG | Score: 0.9593236\n",
      "Entity: New York City | Type: LOC | Score: 0.9991713\n",
      "Entity: Transformers | Type: ORG | Score: 0.99184954\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the named entity recognition pipeline\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "text = \"Hugging Face is a company based in New York City. Its technology is based on Transformers.\"\n",
    "\n",
    "results = ner(text)\n",
    "\n",
    "for entity in results:\n",
    "    print(\"Entity:\", entity['word'], \"| Type:\", entity['entity_group'], \"| Score:\", entity['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Generation**\n",
    "Text generation involves automatically generating text based on a given prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the future, AI will create machines that do things from top down to the point where they can do whatever they want. The goal is to create a better understanding of the individual human being, who they actually represent. We can do this by training\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the text generation pipeline\n",
    "text_generator = pipeline(\"text-generation\")\n",
    "\n",
    "# Generate text\n",
    "result = text_generator(\"In the future, AI will\", max_length=50)\n",
    "print(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question Answering**\n",
    "Question Answering systems can read through texts and provide answers to questions based on the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.2838223874568939, 'start': 51, 'end': 60, 'answer': 'NLP tasks'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the question answering pipeline\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "\n",
    "context = \"Transformers have been adopted for a wide range of NLP tasks.\"\n",
    "\n",
    "result = question_answerer(question=\"What can transformers be used for?\", context=context)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Translation**\n",
    "Translation models can translate text from one language to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision 686f1db (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/waseem/Desktop/Files/Tribe/venv_ml/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:171: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face propose des modèles NLP faciles à utiliser.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the translation pipeline\n",
    "translator = pipeline(\"translation_en_to_fr\")\n",
    "\n",
    "# Translate text\n",
    "result = translator(\"Hugging Face provides easy-to-use NLP models.\", max_length=40)\n",
    "print(result[0]['translation_text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
