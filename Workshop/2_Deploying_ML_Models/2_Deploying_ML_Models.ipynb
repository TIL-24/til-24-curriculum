{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Machine Learning Models with FastAPI\n",
    "\n",
    "This notebook will introduce you to the key aspects of deploying machine learning models using FastAPI. We'll explore setting up a FastAPI server, handling file uploads, and integrating a pre-trained machine learning model for image classification. You'll learn about the essential components such as route creation, asynchronous request handling and forming JSON responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation Guide\n",
    "\n",
    "```bash\n",
    "pip install fastapi uvicorn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to FastAPI\n",
    "\n",
    "What is FastAPI?\n",
    "FastAPI is a modern Python web framework designed explicitly for building high-performance RESTful APIs.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def hello():\n",
    "    return {\"message\": \"Hello, this is your first API with FastAPI\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the above example from the command line using:\n",
    "\n",
    "```bash\n",
    "uvicorn fastapi_hello_world:app --host 0.0.0.0 --port 80\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Building Your First Machine Learning API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### FastAPI App Structure\n",
    "The basic structure of a FastAPI application is straightforward:\n",
    "- **App creation**: An instance of `FastAPI()`.\n",
    "- **Endpoint definition**: Using decorators to define functions for particular HTTP methods at specific API paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from fastapi.responses import JSONResponse\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    image_data = await file.read()\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        predicted_index = output.argmax(1).item()\n",
    "    \n",
    "    return JSONResponse(content={\"predicted_class\": predicted_index})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet illustrates how to define a more complex POST endpoint in FastAPI that handles image data for ML predictions.\n",
    "\n",
    "- `@app.post(\"/predict/\")`: Defines a route that listens for POST requests, where users can send images for classification.\n",
    "- `async def predict(file: UploadFile = File(...))`: The endpoint function is asynchronous, which improves performance by handling requests concurrently. It accepts an uploaded file through the request.\n",
    "- `await file.read()`: Asynchronously reads the uploaded file's data, efficient for handling I/O operations.\n",
    "- `JSONResponse`: Returns the predicted class in a JSON format, making the API suitable for integration with other services or applications that consume JSON.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the API Using Python Requests\n",
    "With the app running, let's use the requests library to send an image to the FastAPI application and receive a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_class': 281}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the FastAPI endpoint\n",
    "url = 'http://localhost:8000/predict/'\n",
    "\n",
    "# Path to the image file\n",
    "file_path = 'imgs/cat.jpeg' \n",
    "\n",
    "# Open the image file in binary mode\n",
    "with open(file_path, 'rb') as f:\n",
    "    # Prepare the request payload as a dictionary\n",
    "    files = {'file': (file_path, f, 'image/jpeg')}\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(url, files=files)\n",
    "\n",
    "# Print the response\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `files = {'file': (file_path, f, 'image/jpeg')}`: Constructs a dictionary for the file payload. This dictionary is formatted to be compatible with HTTP multipart/form-data encoding, which is typically used for file uploads\n",
    "- `response = requests.post(url, files=files)`: Sends a POST request to the specified url with the file data. The files parameter is used to indicate that a file is included in the request.\n",
    "- `response.json()`: Parses the JSON response from the FastAPI server. This method converts the JSON returned by the server into a Python dictionary, allowing easy access to the prediction results or any other data returned by the server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret the predicted class from a ResNet model trained on the ImageNet dataset, we can refer to the ImageNet class index [here](https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/) , which maps each class index to a human-readable label. When the model predicts an integer class index, this index corresponds to a specific label in the ImageNet class list.\n",
    "\n",
    "For example, if the model outputs a prediction of `281`, you can look up this index in the ImageNet label file to find that it corresponds to the class \"tabby,tabby cat\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dockerizing Your API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Containerization and Docker\n",
    "Containerization involves encapsulating an application and its environment into a container that can run on any Docker-enabled system. This ensures consistency across different development and production environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/docker_deployment_1.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/docker_deployment.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dockerfile for FastAPI\n",
    "To dockerize your FastAPI application, you need a Dockerfile that specifies the environment, dependencies, and how to run your app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Docker\n",
    "# Use an official Python runtime as a parent image\n",
    "FROM python:3.9-slim\n",
    "\n",
    "# Set the working directory in the container\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy the current directory contents into the container at /app\n",
    "COPY . /app\n",
    "\n",
    "# Install any needed packages specified in requirements.txt\n",
    "RUN pip install fastapi uvicorn Pillow torchvision python-multipart\n",
    "\n",
    "# Run app.py when the container launches\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Dockerfile begins with `FROM python:3.8-slim`, specifying a base image with Python 3.8. The `WORKDIR` command sets the working directory inside the container.\n",
    "- The `WORKDIR` command sets the working directory inside the container.\n",
    "- The `COPY . /app` command copies the application files from the current directory on the host into the `/app` directory in the container. \n",
    "- Following this, `RUN pip install` installs the Python dependencies\n",
    "- `EXPOSE 80` makes port 80 available outside the container, and the `CMD` command specifies the command to run the FastAPI app using Uvicorn, a lightning-fast ASGI server, on port 80. This setup ensures that the FastAPI application can be easily deployed and run in any environment that supports Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Running a Docker Image\n",
    "To build and run your FastAPI application inside a Docker container, use the following commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "docker build -t myfastapiapp .\n",
    "docker run -p 8000:8000 myfastapiapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This segment outlines the commands needed to build and run a Docker image containing a FastAPI application. \n",
    "- `docker build -t myfastapiapp .` command builds a Docker image from the Dockerfile in the current directory and tags it as `myfastapiapp`.\n",
    "- `docker run -p 8000:80 myfastapiapp` command runs the built Docker image as a container. The `-p 8000:80` option maps port 80 inside the container (where the FastAPI app is running) to port 8000 on the host machine. This mapping allows the FastAPI application to be accessed from the host machine's port 8000, facilitating easy interaction with the API during development or production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the API again using Python Requests\n",
    "With the app running, let's use the requests library to send an image to the FastAPI application and receive a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_class': 281}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the FastAPI endpoint\n",
    "url = 'http://localhost:8000/predict/'\n",
    "\n",
    "# Path to the image file\n",
    "file_path = 'imgs/cat.jpeg' \n",
    "\n",
    "# Open the image file in binary mode\n",
    "with open(file_path, 'rb') as f:\n",
    "    # Prepare the request payload as a dictionary\n",
    "    files = {'file': (file_path, f, 'image/jpeg')}\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(url, files=files)\n",
    "\n",
    "# Print the response\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker Compose\n",
    "\n",
    "Docker Compose simplifies the process of managing multi-container Docker applications by allowing you to define all your services and their configurations in a single `docker-compose.yaml` file. In this example, we will use Docker Compose to:\n",
    "\n",
    "1. Build and run the FastAPI application.\n",
    "2. Expose the application via a specified port.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Create the Docker Compose configuration file, `docker-compose.yml`:\n",
    "\n",
    "```yaml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  fastapi-app:\n",
    "    build:\n",
    "      context: .\n",
    "    ports:\n",
    "      - \"8000:800\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `docker-compose.yml` file is critical for defining how multiple services work together. Here, we use it to describe a single FastAPI service, build it from the local Dockerfile, and map it to a host port so it can be accessed externally.Let's analyze the individual components of the file:\n",
    "\n",
    "- `version: '3.8'`\n",
    "   - Specifies the version of the Docker Compose file format.\n",
    "   - `3.8` is a recent version with improved features and compatibility.\n",
    "\n",
    "- `services:`\n",
    "   - The primary section where we define all the services needed for the application.\n",
    "   - Each service will run as a separate Docker container.\n",
    "\n",
    "- `fastapi-app:`\n",
    "   - Represents the service name for our FastAPI application.\n",
    "   - Contains specific configurations related to this particular service.\n",
    "\n",
    "- `build:`\n",
    "   - Indicates how to build the Docker image for this service.\n",
    "   - `context`: Refers to the directory where Docker will search for the `Dockerfile`.\n",
    "\n",
    "- `ports:`\n",
    "   - Maps internal container ports to the host machine's ports.\n",
    "   - `\"8000:8000\"` maps port `8000` inside the container to port `8000` on the host machine.\n",
    "   - This allows external access to the service through port `8000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Build and run your Docker Compose application using the command:\n",
    "\n",
    "```bash\n",
    "docker-compose up --build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the API again using Python Requests\n",
    "With the app running, let's use the requests library to send an image to the FastAPI application and receive a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predicted_class': 281}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the FastAPI endpoint\n",
    "url = 'http://localhost:8000/predict/'\n",
    "\n",
    "# Path to the image file\n",
    "file_path = 'imgs/cat.jpeg' \n",
    "\n",
    "# Open the image file in binary mode\n",
    "with open(file_path, 'rb') as f:\n",
    "    # Prepare the request payload as a dictionary\n",
    "    files = {'file': (file_path, f, 'image/jpeg')}\n",
    "    \n",
    "    # Send the POST request\n",
    "    response = requests.post(url, files=files)\n",
    "\n",
    "# Print the response\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Stop the application\n",
    "\n",
    "```bash\n",
    "docker-compose down\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Docker Compose allows you to quickly orchestrate multiple containers and manage application dependencies seamlessly. By defining the service configuration in a `docker-compose.yaml` file, we make the FastAPI ML deployment portable, reproducible, and scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this this workshop, we have explored the process of deploying machine learning models using FastAPI, from setting up a basic API to integrating and containerizing the application using Docker for consistent, scalable deployments.\n",
    "\n",
    "We covered a wide range of topics essential for anyone looking to deploy their machine learning models into production environments:\n",
    "\n",
    "- **FastAPI's Essentials**: We began with the basics of FastAPI, appreciating its speed, ease of use, and features like automatic data validation and documentation which make it an excellent choice for ML deployments.\n",
    "- **Machine Learning Integration**: We demonstrated how to integrate a pre-trained machine learning model into a FastAPI application, handling both GET and POST requests.\n",
    "- **Dockerization**: We containerized our FastAPI application using Docker, which not only simplifies deployment across different environments but also aids in achieving consistency and scalability.\n",
    "- **Production Deployment**: Finally, we discussed best practices for deploying our application to production, including considerations for scaling, security, and monitoring.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
